{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "279f7272",
   "metadata": {},
   "source": [
    "# Test Client\n",
    "## 1. Start Ollama cli and LLM \n",
    "To start serving ollama cli\n",
    "``` \n",
    "ollama serve\n",
    "``` \n",
    "To run pull and run a model - replace model name\n",
    "``` \n",
    "ollama run MODEL_NAME\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe65e11",
   "metadata": {},
   "source": [
    "## 2. Set model variable\n",
    "Change model_name string to name of model and version running on ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471ef34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"llama3.2:latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c24cdf-3615-4583-9024-72bb53232099",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core import Settings\n",
    "\n",
    "llm = Ollama(model=model_name, request_timeout=120.0)\n",
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a927e0a2-151d-4a32-8aa3-e08b37cc4e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.tools.mcp import BasicMCPClient, McpToolSpec\n",
    "\n",
    "mcp_client = BasicMCPClient(\"http://mcp-service:8000/sse\")\n",
    "mcp_tools = McpToolSpec(client=mcp_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0a4fe6-83af-4dfd-8c64-bde175905337",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = await mcp_tools.to_tool_list_async()\n",
    "for tool in tools:\n",
    "    print(tool.metadata.name, tool.metadata.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9992a13-a7e7-4b5d-9186-a24a608c8834",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent.workflow import FunctionAgent\n",
    "\n",
    "SYSTEM_PROMPT = \"You are a helpful assistant that can use tools to answer questions.\"\n",
    "\n",
    "async def get_agent():\n",
    "    tool_list = await mcp_tools.to_tool_list_async()\n",
    "    return FunctionAgent(\n",
    "        name=f\"{model_name}Agent\",\n",
    "        description=f\"Agent using {model_name} and MCP tools\",\n",
    "        tools=tool_list,\n",
    "        llm=llm,\n",
    "        system_prompt=SYSTEM_PROMPT\n",
    "    )\n",
    "\n",
    "agent = await get_agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62ecd03",
   "metadata": {},
   "source": [
    "## Start agent\n",
    "Run agent, inputting \"Say hello\" start message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5465de-81b3-405b-9161-0cb96cd13e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.workflow import Context\n",
    "\n",
    "ctx = Context(agent)\n",
    "\n",
    "async def run_agent():\n",
    "    message = \"Say hello\"\n",
    "    response = await agent.run(message, ctx=ctx)\n",
    "    print(\"Agent:\", response)\n",
    "\n",
    "await run_agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60f2037",
   "metadata": {},
   "source": [
    "## Use Echo tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73746870",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await agent.run(\"Please use the echo tool to repeat the message 'Testing 123'\", ctx=ctx)\n",
    "print(\"Agent:\", response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
